# ScenePartner

An iPhone/iPad app for actors to rehearse scenes and record self-tapes with an AI scene partner.

---

## Current Version: v0.1-milestone

> To restore this state at any time: `git checkout v0.1-milestone`

---

## What It Does (v0.1)

ScenePartner lets you import a script, select your character, and rehearse with an AI partner that speaks the other characters' lines. The app works fully offline using on-device TTS, with optional neural voice via ElevenLabs when online.

---

## Feature Status

### ‚úÖ Implemented (v0.1)

**Script Management**
- Paste script as plain text
- Import `.txt` files
- Import `.docx` Word documents (via file picker)
- Local JSON persistence ‚Äî one file per script in Documents directory
- Scripts sorted by last updated

**Script Parsing**
- Scene headings (`SCENE 1`, `INT.`, `EXT.`)
- Character names (ALL-CAPS detection)
- Dialogue lines
- Stage directions `(in parentheses)` or `[brackets]`
- Resilient to inconsistent formatting

**Role Selection**
- Pick which character(s) you play
- AI automatically plays all others
- Improv mode toggle (partner may paraphrase)

**Character Direction**
- Set emotional state per AI character ("desperate, hiding guilt")
- Set scene objective ("convince Alex to stay")
- Tone chips with emoji ‚Äî 15 presets (tense, playful, intimate, angry, etc.)
- Director's free-form notes
- Direction feeds directly into ElevenLabs voice parameters

**Teleprompter**
- Full script display with current line highlighted
- Auto-scroll to current line
- Adjustable font size (14‚Äì72pt)
- Mirror mode (for teleprompter glass setups)
- User-lines-only toggle

**Rehearsal Engine**
- State machine: `idle ‚Üí playingPartner ‚Üí waitingForUser ‚Üí paused ‚Üí finished`
- Deterministic `currentLineIndex` ‚Äî never jumps randomly
- Play / Pause / Resume
- Back (previous dialogue line)
- Jump to scene
- Tap-to-advance (manual fallback)

**Voice System**
- `VoiceEngineProtocol` ‚Äî swap implementations without touching engine
- `SpeechManager` ‚Äî AVSpeechSynthesizer (offline, always works)
- `ElevenLabsVoiceEngine` ‚Äî neural TTS with emotional direction
  - `eleven_turbo_v2_5` model (low latency)
  - Stability mapped from tone (expressive tones ‚Üí lower stability)
  - Style mapped from emotional intensity
  - Falls back to AVSpeech on network error

**Listen Mode**
- `SFSpeechRecognizer` ‚Äî on-device + server recognition
- 0.8s silence detection after last word
- Live audio level meter in UI
- Auto-disabled on simulator (no real mic)
- Graceful fallback to tap-to-advance if recognition fails

**Connectivity**
- `NWPathMonitor` ‚Äî real-time network state
- Offline banner on home screen
- All online features silently skip when offline

**Settings**
- Local Only Mode (disables all network calls)
- ElevenLabs API key (stored in UserDefaults, never in code)
- Voice selection (Daniel / Bella)
- Use AI Voice toggle
- Font size default
- Speech rate / pitch for fallback TTS
- Mirror mode default

---

### üî≤ Planned (v0.2 ‚Äî Self-Tape Recording)

**Phase 1: Camera + Recording**
- [ ] `AVCaptureSession` ‚Äî live camera preview
- [ ] Front/back camera toggle
- [ ] `AVAssetWriter` ‚Äî record video + audio
- [ ] Mix ElevenLabs audio into recording
- [ ] Save to Camera Roll
- [ ] 3-2-1 countdown before recording
- [ ] Slate card (name, scene, take number)

**Phase 2: Take Management**
- [ ] Multiple takes per scene
- [ ] Take browser with thumbnails
- [ ] Mark hero take
- [ ] Delete unwanted takes
- [ ] Trim start/end

**Phase 3: Export & Share**
- [ ] Export to Camera Roll
- [ ] AirDrop share sheet
- [ ] Audio-only export option
- [ ] Casting platform deep links

**Phase 4: Professional Polish**
- [ ] PDF sides import (parse character names)
- [ ] `.docx` sides import (already partially supported)
- [ ] Framing grid overlay
- [ ] Casting session mode (group scenes)
- [ ] Post-run coaching feedback (via AI)
- [ ] Find My Place (AI line recovery)

---

## Architecture

```
Views (SwiftUI)
  ScriptListView ‚Üí RoleSelectionView ‚Üí DirectionView ‚Üí RehearsalView
                                                      ‚Üí TeleprompterView

Engines / ViewModels
  RehearsalEngine    ‚Äî state machine, drives playback
  TeleprompterEngine ‚Äî scroll, font, mirror
  SpeechRecognizer   ‚Äî listen mode (SFSpeechRecognizer)
  AppSettings        ‚Äî @AppStorage user prefs

Service Layer
  ScriptStore        ‚Äî CRUD + JSON persistence
  ScriptParser       ‚Äî raw text ‚Üí Script model
  VoiceEngineProtocol ‚Üê SpeechManager (AVSpeech, offline)
                      ‚Üê ElevenLabsVoiceEngine (neural, online)
  ToneEngine         ‚Äî tone tags ‚Üí TTS parameters
  ConnectivityMonitor ‚Äî NWPathMonitor

Data Models
  Script, Scene, Line, Character
  RehearsalState, VoiceProfile
  SceneDirection, CharacterDirection
  ToneAnalysis (online AI, future)
```

---

## Setup

### Requirements
- Xcode 16+ (built with Xcode 26 beta)
- iOS 17+ deployment target
- Physical device for listen mode (simulator mic unreliable)

### Run
1. Clone: `git clone https://github.com/chgallegos/ScenePartner.git`
2. Open `ScenePartner/ScenePartner/ScenePartner.xcodeproj`
3. Select your device or simulator
4. **‚åòR** to build and run

### ElevenLabs Voice (optional)
1. Sign up at [elevenlabs.io](https://elevenlabs.io)
2. Create an API key with **Text to Speech** access
3. In the app: Settings ‚Üí Use AI Voice ‚Üí paste key

---

## Script Format

```
SCENE 1

ALEX
I can't believe you did that.
(beat)

JAMIE
I had to. There was no other way.
```

- ALL-CAPS name alone on a line = character speaker
- `(parenthetical)` or `[bracket]` = stage direction
- `SCENE N`, `INT.`, `EXT.` = scene heading
- Blank lines reset the current speaker

---

## Restoring the Milestone

```bash
git checkout v0.1-milestone
```

To return to latest:
```bash
git checkout main
```

---

## Tech Stack
- Swift 5 / SwiftUI
- AVFoundation (TTS, audio session, future: recording)
- Speech framework (SFSpeechRecognizer)
- Network framework (NWPathMonitor)
- ElevenLabs REST API (optional)
- No third-party dependencies
